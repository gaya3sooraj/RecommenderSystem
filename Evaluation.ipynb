{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc31f291",
   "metadata": {},
   "source": [
    "# Evaluating Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f984548",
   "metadata": {},
   "source": [
    "## Recommender System\n",
    "A recommender system is an intelligent system that predicts the rating and preferences of users on products. The primary application of recommender systems is finding a relationship between user and products in order to maximise the user-product engagement. The major application of recommender systems is in suggesting related video or music for generating a playlist for the user when they are engaged with a related item. In this project, we are using movie data to build a recommender system and evaluate its performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a68d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries and modules\n",
    "from surprise import Reader, Dataset, SVD, accuracy, KNNBaseline\n",
    "from surprise.model_selection import train_test_split, KFold, LeaveOneOut\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7098b7e4",
   "metadata": {},
   "source": [
    "## Database\n",
    "In this project we are evaluating the efficiency of the recommender system based on five different metrics. The dataset is called MovieLens and can be found [here](https://grouplens.org/datasets/movielens/25m/). MovieLens 25M dataset contains 25 million ratings and one million tag applications applied to 62,000 movies by 162,000 users. In this report we are only using the 'ratings.csv' dataset. The dataset contains four features - user Id, movie Id, movie rating and timestamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e67e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset path\n",
    "ratingsPath = '/MyRecSystemProject/Data/ratings.csv'\n",
    "#Load data\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file(ratingsPath, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8dae1b",
   "metadata": {},
   "source": [
    "## Rating Prediction\n",
    "In this section, we will split the dataset into train set and test set. The test set is 25% of the dataset. We use SVD algorithm for the model. There are other algorithms as well in the surprise module, but the main focus of this project is to understand different evaluation techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19deec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=.25, random_state=1)\n",
    "\n",
    "#Building recommendation model\n",
    "algo = SVD(random_state=10)\n",
    "algo.fit(train_data)\n",
    "\n",
    "#Computing recommendations\n",
    "predictions = algo.test(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c705d84d",
   "metadata": {},
   "source": [
    "## Evaluating our model\n",
    "\n",
    "### 1. Accuracy\n",
    "\n",
    "There are two ways to compute the accuracy of a recommender model.\n",
    "\n",
    "- MAE (Mean Absolute Error) \n",
    "\n",
    "$$ \\frac{\\sum_{i=1}^n |y_i - x_i|}{n}, $$ where $y_i$ is the prediction and $x_i$ is the actual rating.\n",
    "\n",
    "- RMSE (Root Mean Square Error)\n",
    "\n",
    "$$ \\sqrt{\\frac{\\sum_{i=1}^n (y_i - x_i)^2}{n}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f7eb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.9033701087151801\n",
      "MAE:  0.6977882196132263\n"
     ]
    }
   ],
   "source": [
    "#Evaluating accuracy of model\n",
    "rmse = accuracy.rmse(predictions, verbose=False)\n",
    "mae = accuracy.mae(predictions, verbose=False)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129749c",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03307c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 1\n",
      "RMSE:  0.8972015162077746\n",
      "MAE:  0.6914804528784515\n",
      "\n",
      "Fold: 2\n",
      "RMSE:  0.9033188926872354\n",
      "MAE:  0.6941806379758839\n",
      "\n",
      "Fold: 3\n",
      "RMSE:  0.8977920573434492\n",
      "MAE:  0.6906677490570959\n",
      "\n",
      "Fold: 4\n",
      "RMSE:  0.8917878167131393\n",
      "MAE:  0.6862092651080182\n",
      "\n",
      "Fold: 5\n",
      "RMSE:  0.8885238587079475\n",
      "MAE:  0.6851851525669552\n",
      "\n",
      "Mean RMSE:  0.895724828331909\n",
      "Mean MAE:  0.689544651517281\n"
     ]
    }
   ],
   "source": [
    "#Creating n Folds\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "c=0 \n",
    "rmse_list=[] #empty list for storing rmse of each fold\n",
    "mae_list=[] #empty list for storing mae of each fold\n",
    "\n",
    "for traindata, testdata in kf.split(data):\n",
    "    c+=1\n",
    "    print(\"\\nFold:\", c)\n",
    "    algo.fit(traindata)\n",
    "    predictions = algo.test(testdata)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"MAE: \", mae)\n",
    "    \n",
    "print(\"\\nMean RMSE: \", sum(rmse_list) / len(rmse_list))\n",
    "print(\"Mean MAE: \", sum(mae_list) / len(mae_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db3236",
   "metadata": {},
   "source": [
    "### 2. Hit Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8c0f6",
   "metadata": {},
   "source": [
    "The idea is to generate top-N recommendations for all of the users in the test set and if one of the recommendations in a user's top-N recommendations is something the user actually rated, consider that as a hit. Then just sum all of the hits in the top-end recommendations for every user in the test set, divide by the number of users, and that gives us the hit rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a496c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTopN(predictions, n=10, minimumRating=4.0):\n",
    "    topN = defaultdict(list)\n",
    "\n",
    "    for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
    "        if (estimatedRating >= minimumRating):\n",
    "            topN[int(userID)].append((int(movieID), estimatedRating))\n",
    "\n",
    "    for userID, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[int(userID)] = ratings[:n]\n",
    "\n",
    "    return topN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ab580",
   "metadata": {},
   "source": [
    "We compute the top-N recommendations for each user in our training data, and intentionally remove one of those items from that user's training data. We then test our recommender system's ability to recommend that item that was left out in the top-N results it creates for that user in the testing phase. So we measure our ability to recommend an item in a top-N list for each user that was left out from the training data. This method is called Leave-One-Out Cross-Validation, or LOOCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac60faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loocv = LeaveOneOut(n_splits=1, random_state=1)\n",
    "\n",
    "for traindata, testdata in loocv.split(data):\n",
    "    #Train model without left-out ratings\n",
    "    algo.fit(traindata)\n",
    "    #Predicts ratings for left-out ratings only\n",
    "    leftout_predictions = algo.test(testdata)\n",
    "    #Build predictions for all ratings not in the training set\n",
    "    big_test_set = traindata.build_anti_testset()  \n",
    "    all_predictions = algo.test(big_test_set)\n",
    "\n",
    "    #Compute top 10 recs for each user\n",
    "    top_N_predicted = GetTopN(all_predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3032c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-N movies with ratings for each user....\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>V</th>\n",
       "      <th>VI</th>\n",
       "      <th>VII</th>\n",
       "      <th>VIII</th>\n",
       "      <th>IX</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(46578, 4.439161446506118)</td>\n",
       "      <td>(2064, 4.41610463184011)</td>\n",
       "      <td>(969, 4.391065310537569)</td>\n",
       "      <td>(1147, 4.390537149207635)</td>\n",
       "      <td>(926, 4.38618890237767)</td>\n",
       "      <td>(6807, 4.359389472173928)</td>\n",
       "      <td>(1945, 4.348071719852454)</td>\n",
       "      <td>(48516, 4.325914625773898)</td>\n",
       "      <td>(1228, 4.306747177463255)</td>\n",
       "      <td>(111, 4.302574693285729)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3462, 4.306963213695675)</td>\n",
       "      <td>(905, 4.2795135127296255)</td>\n",
       "      <td>(969, 4.273121970391215)</td>\n",
       "      <td>(69844, 4.25212438541356)</td>\n",
       "      <td>(3683, 4.246527927502107)</td>\n",
       "      <td>(46578, 4.228819648953076)</td>\n",
       "      <td>(86882, 4.194861845324719)</td>\n",
       "      <td>(926, 4.191485407784973)</td>\n",
       "      <td>(50, 4.188700290029376)</td>\n",
       "      <td>(3435, 4.165398859879112)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(318, 5)</td>\n",
       "      <td>(2318, 5)</td>\n",
       "      <td>(2762, 5)</td>\n",
       "      <td>(1035, 5)</td>\n",
       "      <td>(1193, 5)</td>\n",
       "      <td>(1221, 5)</td>\n",
       "      <td>(1247, 5)</td>\n",
       "      <td>(111, 5)</td>\n",
       "      <td>(1250, 5)</td>\n",
       "      <td>(745, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1217, 4.748149172147203)</td>\n",
       "      <td>(969, 4.707653668367146)</td>\n",
       "      <td>(7502, 4.674733786162311)</td>\n",
       "      <td>(922, 4.659033619452552)</td>\n",
       "      <td>(908, 4.6447331321575795)</td>\n",
       "      <td>(6016, 4.640703426996425)</td>\n",
       "      <td>(905, 4.6334480044019335)</td>\n",
       "      <td>(318, 4.6331733296216235)</td>\n",
       "      <td>(904, 4.624272736284148)</td>\n",
       "      <td>(3035, 4.5814425881237)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(318, 4.318653035294874)</td>\n",
       "      <td>(858, 4.131556078432512)</td>\n",
       "      <td>(898, 4.119206097367941)</td>\n",
       "      <td>(1172, 4.07033775580625)</td>\n",
       "      <td>(1207, 4.0539398583844495)</td>\n",
       "      <td>(2318, 4.031520010772444)</td>\n",
       "      <td>(1228, 4.026020833632793)</td>\n",
       "      <td>(3462, 4.006775577984113)</td>\n",
       "      <td>(926, 4.000805310451805)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  I                         II  \\\n",
       "User_id                                                          \n",
       "2        (46578, 4.439161446506118)   (2064, 4.41610463184011)   \n",
       "3         (3462, 4.306963213695675)  (905, 4.2795135127296255)   \n",
       "4                          (318, 5)                  (2318, 5)   \n",
       "5         (1217, 4.748149172147203)   (969, 4.707653668367146)   \n",
       "6          (318, 4.318653035294874)   (858, 4.131556078432512)   \n",
       "\n",
       "                               III                         IV  \\\n",
       "User_id                                                         \n",
       "2         (969, 4.391065310537569)  (1147, 4.390537149207635)   \n",
       "3         (969, 4.273121970391215)  (69844, 4.25212438541356)   \n",
       "4                        (2762, 5)                  (1035, 5)   \n",
       "5        (7502, 4.674733786162311)   (922, 4.659033619452552)   \n",
       "6         (898, 4.119206097367941)   (1172, 4.07033775580625)   \n",
       "\n",
       "                                  V                          VI  \\\n",
       "User_id                                                           \n",
       "2           (926, 4.38618890237767)   (6807, 4.359389472173928)   \n",
       "3         (3683, 4.246527927502107)  (46578, 4.228819648953076)   \n",
       "4                         (1193, 5)                   (1221, 5)   \n",
       "5         (908, 4.6447331321575795)   (6016, 4.640703426996425)   \n",
       "6        (1207, 4.0539398583844495)   (2318, 4.031520010772444)   \n",
       "\n",
       "                                VII                        VIII  \\\n",
       "User_id                                                           \n",
       "2         (1945, 4.348071719852454)  (48516, 4.325914625773898)   \n",
       "3        (86882, 4.194861845324719)    (926, 4.191485407784973)   \n",
       "4                         (1247, 5)                    (111, 5)   \n",
       "5         (905, 4.6334480044019335)   (318, 4.6331733296216235)   \n",
       "6         (1228, 4.026020833632793)   (3462, 4.006775577984113)   \n",
       "\n",
       "                                IX                          X  \n",
       "User_id                                                        \n",
       "2        (1228, 4.306747177463255)   (111, 4.302574693285729)  \n",
       "3          (50, 4.188700290029376)  (3435, 4.165398859879112)  \n",
       "4                        (1250, 5)                   (745, 5)  \n",
       "5         (904, 4.624272736284148)    (3035, 4.5814425881237)  \n",
       "6         (926, 4.000805310451805)                       None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top-N movies with ratings for each user....\\n \")\n",
    "top_n_recommendations = pd.DataFrame.from_dict(top_N_predicted, orient='index', \n",
    "                           columns=['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X'])\n",
    "                           \n",
    "top_n_recommendations.index.name = \"User_id\"\n",
    "top_n_recommendations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2397a416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_recommendations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff1c5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HitRate(topNPredicted, leftOutPredictions):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "\n",
    "    #For each left-out rating\n",
    "    for leftOut in leftOutPredictions:\n",
    "        userID = leftOut[0]\n",
    "        leftOutMovieID = leftOut[1]\n",
    "        #Is it in the predicted top 10 for this user?\n",
    "        hit = False\n",
    "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "            if (int(leftOutMovieID) == int(movieID)):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit) :\n",
    "            hits += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    #Compute overall precision\n",
    "    return hits/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5536eb5",
   "metadata": {},
   "source": [
    "#### Cumulative Hit Rate \n",
    "It means that we discard the hits if our predicted ratings are below some threshold. This way we won't recommend items to a user that we think they won't actually enjoy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31ec8b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "\n",
    "    #For each left-out rating\n",
    "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "        #Only look at ability to recommend things the users actually liked...\n",
    "        if (actualRating >= ratingCutoff):\n",
    "            #Is it in the predicted top 10 for this user?\n",
    "            hit = False\n",
    "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "                if (int(leftOutMovieID) == movieID):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit) :\n",
    "                hits += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "    #Compute overall precision\n",
    "    return hits/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49d238",
   "metadata": {},
   "source": [
    "#### Rating Hit Rate\n",
    "The break down of hit rate by predicted rating score. It is a good way to get an idea of the distribution of how good the algorithm thinks recommended movies are, that actually get a hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a072f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RatingHitRate(topNPredicted, leftOutPredictions):\n",
    "    hits = defaultdict(float)\n",
    "    total = defaultdict(float)\n",
    "\n",
    "    #For each left-out rating\n",
    "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "        #Is it in the predicted top N for this user?\n",
    "        hit = False\n",
    "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "            if (int(leftOutMovieID) == movieID):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit) :\n",
    "            hits[actualRating] += 1\n",
    "\n",
    "        total[actualRating] += 1\n",
    "\n",
    "    #Compute overall precision\n",
    "    for rating in sorted(hits.keys()):\n",
    "        print (rating, hits[rating] / total[rating])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b521e04d",
   "metadata": {},
   "source": [
    "#### Average reciprocal hit rate\n",
    "This metric accounts for where in the top-N list the hits appear. So we end up getting more successful at recommending a movie in the top slot, than in the bottom slot. This is an important and user-focused metric since users tend to focus on the beginning of lists. The only difference is that instead of adding up the number of hits, we add up the reciprocal rank of each hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24049cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageReciprocalHitRank(topNPredicted, leftOutPredictions):\n",
    "    summation = 0\n",
    "    total = 0\n",
    "    #For each left-out rating\n",
    "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "        #Is it in the predicted top N for this user?\n",
    "        hitRank = 0\n",
    "        rank = 0\n",
    "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "            rank = rank + 1\n",
    "            if (int(leftOutMovieID) == movieID):\n",
    "                hitRank = rank\n",
    "                break\n",
    "        if (hitRank > 0) :\n",
    "            summation += 1.0 / hitRank\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    return summation / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6aaf656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hit Rate:  0.029806259314456036\n"
     ]
    }
   ],
   "source": [
    "#Check how often we recommended a movie the user actually rated\n",
    "print(\"\\nHit Rate: \", HitRate(top_N_predicted, leftout_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0387f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rHR (Hit Rate by Rating value): \n",
      "3.5 0.017241379310344827\n",
      "4.0 0.0425531914893617\n",
      "4.5 0.020833333333333332\n",
      "5.0 0.06802721088435375\n"
     ]
    }
   ],
   "source": [
    "#Break down hit rate by rating value\n",
    "print(\"\\nrHR (Hit Rate by Rating value): \")\n",
    "RatingHitRate(top_N_predicted, leftout_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "540f6873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cHR (Cumulative Hit Rate, rating >= 4):  0.04960835509138381\n"
     ]
    }
   ],
   "source": [
    "#See how often we recommended a movie the user actually liked\n",
    "print(\"\\ncHR (Cumulative Hit Rate, rating >= 4): \", CumulativeHitRate(top_N_predicted, leftout_predictions, 4.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1316928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ARHR (Average Reciprocal Hit Rank):  0.0111560570576964\n"
     ]
    }
   ],
   "source": [
    "#Compute ARHR\n",
    "print(\"\\nARHR (Average Reciprocal Hit Rank): \", AverageReciprocalHitRank(top_N_predicted, leftout_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d95b488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x13b910940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing item similarities \n",
    "full_train_data = data.build_full_trainset()\n",
    "sim_algo = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "sim_algo.fit(full_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a27b7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing complete recommendations, no hold outs\n",
    "algo.fit(full_train_data)\n",
    "big_test_data = full_train_data.build_anti_testset()\n",
    "predictions = algo.test(big_test_data)\n",
    "top_N_predicted = GetTopN(predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96081a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-N movies with ratings for each user....\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(641, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top-N movies with ratings for each user....\\n \")\n",
    "top_n_recommendations = pd.DataFrame.from_dict(top_N_predicted, orient='index', \n",
    "                           columns=['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X'])\n",
    "                           \n",
    "top_n_recommendations.index.name = \"User_id\"\n",
    "top_n_recommendations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbf1ead",
   "metadata": {},
   "source": [
    "### 3. Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6267ff",
   "metadata": {},
   "source": [
    "Coverage is the percentage of possible recommendations the system is able to provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02521ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserCoverage(topNPredicted, numUsers, ratingThreshold=0):\n",
    "    hits = 0\n",
    "    for userID in topNPredicted.keys():\n",
    "        hit = False\n",
    "        for movieID, predictedRating in topNPredicted[userID]:\n",
    "            if (predictedRating >= ratingThreshold):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit):\n",
    "            hits += 1\n",
    "\n",
    "    return hits / numUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cbc791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User coverage:  0.9552906110283159\n"
     ]
    }
   ],
   "source": [
    "#Print user coverage with a minimum predicted rating of 4.0:\n",
    "print(\"\\nUser coverage: \", UserCoverage(top_N_predicted, full_train_data.n_users, ratingThreshold=4.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a8a30",
   "metadata": {},
   "source": [
    "### 4. Diversity\n",
    "Diversity is a measure of how broad a variety of items the recommender system is putting in front of users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47ad4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diversity(topNPredicted, simsAlgo):\n",
    "    n = 0\n",
    "    total = 0\n",
    "    simsMatrix = simsAlgo.compute_similarities()\n",
    "    for userID in topNPredicted.keys():\n",
    "        \n",
    "        pairs = it.combinations(topNPredicted[userID], 2)\n",
    "        for pair in pairs:\n",
    "            movie1 = pair[0][0]\n",
    "            movie2 = pair[1][0]\n",
    "            \n",
    "            innerID1 = simsAlgo.trainset.to_inner_iid(str(movie1))\n",
    "            innerID2 = simsAlgo.trainset.to_inner_iid(str(movie2))\n",
    "            \n",
    "            similarity = simsMatrix[innerID1][innerID2]\n",
    "            \n",
    "            total += similarity\n",
    "            n += 1\n",
    "\n",
    "    S = total / n\n",
    "    return (1-S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "026c0f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Diversity:  0.9665208258150911\n"
     ]
    }
   ],
   "source": [
    "#Measure diversity of recommendations:\n",
    "print(\"\\nDiversity: \", Diversity(top_N_predicted, sim_algo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b3bf2",
   "metadata": {},
   "source": [
    "### 5. Novelty\n",
    "Novelty is a measure of how popular the movies are that are being recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a141487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPopularityRanks():\n",
    "    ratings = defaultdict(int)\n",
    "    rankings = defaultdict(int)\n",
    "    with open(ratingsPath, newline='') as csvfile:\n",
    "        ratingReader = csv.reader(csvfile)\n",
    "        next(ratingReader)\n",
    "        for row in ratingReader:\n",
    "            movieID = int(row[1])\n",
    "            ratings[movieID] += 1\n",
    "    rank = 1\n",
    "    for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "        rankings[movieID] = rank\n",
    "        rank += 1\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d6aee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Novelty(topNPredicted, rankings):\n",
    "    n = 0\n",
    "    total = 0\n",
    "    for userID in topNPredicted.keys():\n",
    "        for rating in topNPredicted[userID]:\n",
    "            movieID = rating[0]\n",
    "            rank = rankings[movieID]\n",
    "            total += rank\n",
    "            n += 1\n",
    "    return total / n  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfc5bd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Novelty (average popularity rank):  491.5767777960256\n"
     ]
    }
   ],
   "source": [
    "#Computing movie popularity ranks so we can measure novelty\n",
    "rankings = getPopularityRanks()\n",
    "#Measure novelty (average popularity rank of recommendations):\n",
    "print(\"\\nNovelty (average popularity rank): \", Novelty(top_N_predicted, rankings))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
